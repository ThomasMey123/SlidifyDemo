cutTrain1<-cut2(training$FlyAsh,g=3)
head(cutTrain1)
plot(training$CompressiveStrength,col=cutTrain1,main="FlyAsh")
cutTrain1<-cut2(training$Water,g=3)
head(cutTrain1)
plot(training$CompressiveStrength,col=cutTrain1,main="Water")
cutTrain1<-cut2(training$Superplasticizer,g=3)
head(cutTrain1)
plot(training$CompressiveStrength,col=cutTrain1,main="Superplasticizer")
cutTrain1<-cut2(training$CoarseAggregate,g=3)
head(cutTrain1)
plot(training$CompressiveStrength,col=cutTrain1,main="CoarseAggregate")
cutTrain1<-cut2(training$FineAggregate,g=3)
head(cutTrain1)
plot(training$CompressiveStrength,col=cutTrain1,main="FineAggregate")
cutTrain1<-cut2(training$Age,g=3)
head(cutTrain1)
plot(training$CompressiveStrength,col=cutTrain1,main="Age")
cutTrain1<-cut2(training$FlyAsh,g=5)
head(cutTrain1)
plot(training$CompressiveStrength,col=cutTrain1,main="FlyAsh")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
hist(training$SuperPlasticizer)
hist(log10(training$SuperPlasticizer+1)
hist(log10(training$SuperPlasticizer+1))
hist(log10(training$SuperPlasticizer+1))
hist(training$SuperPlasticizer)
str(training)
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer+1))
summary(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
training$col
colnames(training)
grep( "^IL*",colnames(training))
cols<-grep( "^IL*",colnames(training))
training[cols,]
head(training[,cols])
cols<-grep( "^IL",colnames(training))
head(training[,cols])
head(training[,cols])
preObj<-preProcess(t2,method="pca")
t2<-training[,cols]
preObj<-preProcess(t2,method="pca")
preObj
t2<-training[,cols]
preObj<-preProcess(t2,method="pca",pcaComp=7)
preObj
preObj<-preProcess(t2,method="pca",pcaComp=8)
preObj
preObj<-preProcess(t2,method="pca",pcaComp=9)
preObj
preObj<-preProcess(t2,method="pca",pcaComp=10)
preObj
preObj<-preProcess(t2,method="pca",thres=0.9)
preObj
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
t2<-training[,c(1,cols)]
head(t2)
preObj<-preProcess(t2,method="pca",thres=0.8)
preObj
lm2<-predict(preObj, t2)
lm2<-predict(preObj, t2,method="glm")
lm1<-predict(t2,method="glm")
lm1<-predict(diagnosis~.,data=t2,method="glm")
lm1<-train(diagnosis~.,data=t2,method="glm")
lm1
lm2
lm1
preObj
lm2<-fit(preObj, t2,method="glm")
t
lm2<-predict(preObj, t2,method="glm")
head(lm2)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
M<-abs(cor(training[,-58]))
# set the diagonal to 0 since we know that this is highly correlated
diag(M)<-0
# of the remaining variables - which ones have a high correlation?
which(M>0.8,arr.ind=T)
#how to perform PCA
smallSpam<-spam[,c(32,34)]
prComp<-prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
#One more example
typeColor<-((spam$type=="spam")*1+1)
prComp<-prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
#with the caret package
preProc<-preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC<-predict(preProc,log10(training[,-58]+1))
plot(spamPC[,1], spamPC[,2],col=typeColor)
preProc<-preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC<-predict(preProc,log10(training[,-58]+1))
modelFit<-train(training$type~.,method="glm",data=trainPC)
testPC<-predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type, predict(modelFit,testPC))
cols<-grep( "^IL",colnames(training))
t2<-training[,c(1,cols)]
preObj<-preProcess(t2,method="pca",thres=0.8)
cols<-grep( "^IL",colnames(training))
t2<-training[,c(1,cols)]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
cols<-grep( "^IL",colnames(training))
t2<-training[,c(1,cols)]
preObj<-preProcess(t2,method="pca",thres=0.8)
data2<-predict(preObj, t2,method="glm")
lm2<-train(diagnosis~.,data=data2,method="glm")
lm1<-train(diagnosis~.,data=t2,method="glm")
lm2
lm1
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.5, list =FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
cols<-grep( "^IL",colnames(training))
t2<-training[,c(1,cols)]
preObj<-preProcess(t2,method="pca",thres=0.8)
data2<-predict(preObj, t2,method="glm")
lm2<-train(diagnosis~.,data=data2,method="glm")
lm1<-train(diagnosis~.,data=t2,method="glm")
lm2
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
cols<-grep( "^IL",colnames(training))
t2<-training[,c(1,cols)]
preObj<-preProcess(t2,method="pca",thres=0.8)
data2<-predict(preObj, t2,method="glm")
lm2<-train(diagnosis~.,data=data2,method="glm")
lm1<-train(diagnosis~.,data=t2,method="glm")
lm2
lm1
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
str(training)
summary(training)
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer+1))
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer))
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer+1))
data(iris)
library(ggplot2)
names(iris)
table(iris$species)
table(iris$species)
table(iris$Species)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
library(caret)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(Training);dim(testing)
dim(training);dim(testing)
qplot(Petal.Width,Sepal.Width,color=Species,data=training)
modFit<-train(Species~.,method="rpart",data=training)
modFit$finalModel
plot(modFit$Final,uniform=TRUE,main="classification tree")
plot(modFit$finalModel,uniform=TRUE,main="classification tree")
text(modFit$finalModel, use.n =TRUE, all=TRUE, cex=0.8)
library(rattle)
install.packages("rattle")
library(rattle)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
library(caret)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training);dim(testing)
qplot(Petal.Width,Sepal.Width,color=Species,data=training)
modFit<-train(Species~.,method="rpart",data=training)
modFit$finalModel
plot(modFit$finalModel,uniform=TRUE,main="classification tree")
text(modFit$finalModel, use.n =TRUE, all=TRUE, cex=0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart.plot")
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
library(caret)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training);dim(testing)
qplot(Petal.Width,Sepal.Width,color=Species,data=training)
modFit<-train(Species~.,method="rpart",data=training)
modFit$finalModel
plot(modFit$finalModel,uniform=TRUE,main="classification tree")
text(modFit$finalModel, use.n =TRUE, all=TRUE, cex=0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=training)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(ozone, package="ElemStatLearn")
ozone<-ozone[order(ozone$ozone),]
head(ozone)
ll<-matrix(NA,nrow=10, ncol=155)
for(i in 1:10) {
ss<-sample(1:dim(ozone)[1],replace=T)
ozone0<-ozone[ss,]
ozone0<-ozone0[order(ozone0$ozone),]
loess<- loess(temperature ~ ozone, data=ozone0,span=0.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
ll<-matrix(NA,nrow=10, ncol=155)
for(i in 1:10) {
ss<-sample(1:dim(ozone)[1],replace=T)
ozone0<-ozone[ss,]
ozone0<-ozone0[order(ozone0$ozone),]
loess0<- loess(temperature ~ ozone, data=ozone0,span=0.2)
ll[i,]<-predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature, pch=19,cex=0.5)
for(i in 1:10) {lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155, apply(ll,2,mean),col="red",lwd=2)
predictors = data.frame(ozone=ozone$ozone)
temperature=ozone$temperature
treebag<-bag(predictors, temperature, B=10,
bagControl=bagControl(fit = ctreeBag$fit,
predict= ctreeBag$pred,
aggregate= ctreeBag$aggregate))
install.packages("party")
predictors = data.frame(ozone=ozone$ozone)
temperature=ozone$temperature
treebag<-bag(predictors, temperature, B=10,
bagControl=bagControl(fit = ctreeBag$fit,
predict= ctreeBag$pred,
aggregate= ctreeBag$aggregate))
plot(ozone$ozone, temperature, col='lightgrey',pch=19)
points(ozone$ozone, predict(treebag$fits[[1]]$fit,predictors),pch=19,col="red")
points(ozone$ozone, predict(treebag,predictors),pch=19,col="blue")
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
library(caret)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
modFit<-train(Species~.,method="rf",data=training,prox=TRUE)
modFit
getTree(modFit$finalModel,k=2)
irisP<-classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP<-as.data.frame(irisP)
p<-qplot(Petal.Width,Petal.Length,col=Species,data=training)
p+geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species), size=5,shape=4,data=irisP)
irisP<-classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP<-as.data.frame(irisP)
irisP$Species<-rownames(irisP)
p<-qplot(Petal.Width,Petal.Length,col=Species,data=training)
p+geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species), size=5,shape=4,data=irisP)
irisP
pred<-predict(modFit,testing);
testing$predRight<-pred==testing$Species
table(pred,testing$Species)
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing)
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing, main="newdata Predictions")
modFit<-train(wage~.,method="gbm", data=training,verbose=FALSE)
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
modFit<-train(wage~.,method="gbm", data=training,verbose=FALSE)
modFit<-train(wage~.,method="gbm", data=training,verbose=FALSE)
modFit
qplot(predict(modFit,testing),wage,data=training)
qplot(predict(modFit,testing),wage,data=testing)
?train
library(caret)
?train
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inBuild<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
validation<-Wage[-inBuild,];
buildData<-Wage[inBuild,]
inTrain<-createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
training<-buildData[inTrain,]
testing<-buildData[-inTrain,]
dim(training)
dim(testing)
mod1<-train(wage~.,method="glm",data=training,verbose=FALSE,warning=FALSE)
mod1<-train(wage~.,method="glm",data=training,verbose=FALSE)
library(caret)
install.packages("kernlab")
install.packages("caret")
install.packages("minga")
install.packages("minqa")
install.packages("ISLR")
install.packages("HMisc")
install.packages("Hmisc")
install.packages("RANN")
install.packages("e1071")
install.packages("rattle")
install.packages("rattle")
install.packages("GTK+")
install.packages("RGtk2")
install.packages("rattle")
install.packages("RGtk2")
install.packages("rattle")
library(RGtk2)
install.packages("rpart")
install.packages("quantmod")
install.packages("forecast")
library("rpart")
install.packages("rpart.plot")
install.packages("ElemStatLearn")
install.packages("party")
data(iris)
library(ggplot2)
names(iris)
library(caret)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
modFit<-train(Species~.,method="rf",data=training,prox=TRUE)
modFit<-train(Species~.,method="rf",data=training,prox=TRUE)
modFit
getTree(modFit$finalModel,k=2)
#Class centers
irisP<-classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP<-as.data.frame(irisP)
irisP$Species<-rownames(irisP)
p<-qplot(Petal.Width,Petal.Length,col=Species,data=training)
p+geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species), size=5,shape=4,data=irisP)
pred<-predict(modFit,testing);
testing$predRight<-pred==testing$Species
table(pred,testing$Species)
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing, main="newdata Predictions")
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
modFit<-train(wage~.,method="gbm", data=training,verbose=FALSE)
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
library(caret)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
modFit<-train(wage~.,method="gbm", data=training,verbose=FALSE)
install.packages("plyr")
install.packages("plyr")
install.packages("plyr")
library(caret)
library(ggplot2)
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
modFit<-train(wage~.,method="gbm", data=training,verbose=FALSE)
modFit
qplot(predict(modFit,testing),wage,data=testing)
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inBuild<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
validation<-Wage[-inBuild,];
buildData<-Wage[inBuild,]
inTrain<-createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
training<-buildData[inTrain,]
testing<-buildData[-inTrain,]
dim(training)
dim(testing)
mod1<-train(wage~.,method="glm",data=training,verbose=FALSE)
mod2<-train(wage~.,method="rf",data=training,trControl=trainControl(method="cv"),number=3)
pred1<-predict(mod1,testing)
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inBuild<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
validation<-Wage[-inBuild,];
buildData<-Wage[inBuild,]
inTrain<-createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
library(caret)
library(ISLR)
data(Wage)
Wage<-subset(Wage,select=-c(logwage))
inBuild<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
validation<-Wage[-inBuild,];
buildData<-Wage[inBuild,]
inTrain<-createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
training<-buildData[inTrain,]
testing<-buildData[-inTrain,]
dim(training)
dim(testing)
install.packages("glm")
mod1<-train(wage~.,method="glm",data=training,verbose=FALSE)
warnings()
mod1<-train(wage~.,method="glm",data=training)
warnings()
mod2<-train(wage~.,method="rf",data=training,trControl=trainControl(method="cv"),number=3)
data(economics, package ="ggplot2")
econ<-transform(economics, date=as.character(date))
m1<-mPlot(x="date", y=c("psavert","uempmed"), type = "Line", data=econ)
library(rCharts)
m1<-mPlot(x="date", y=c("psavert","uempmed"), type = "Line", data=econ)
m1$set(pointSize=0, lineWidth=1)
m1
map3<-Leaflet$new()
map3$setView(c(51.505,-0.09), zoom=13)
map3$marker(c(51.5,-0.09), bindPopup="<p>I am a popup <p>")
map3$marker(c(51.495,-0.083), bindPopup="<p>I am another popup <p>")
map3
usp<-reshape2::melt(USPersonalExpenditure)
usp$Var2<-as.numeric(as.POSIXct(paste0(usp$Var2,"-01-01")))
p4<-Rickshaw$new()
p4$layer(value ~Var2, group ="Var1", data = usp, type = "area", width=560)
p4$set(slider=TRUE)
p4
install.packages("googleVis")
suppressPackageStartupMessages(library(googleVis))
suppressPackageStartupMessages(library(googleVis))
M<-gvisMotionChart(Fruits, "Fruit", "Year", options=list(width=600, height=400))
print(M,chart)
print(M,"chart")
M
plot(M)
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
install_github('ramnathv/slidify')
library(slidify)
setwd("~/Thomas/coursera/09-BuildingDataProducts")
author("first_deck")
